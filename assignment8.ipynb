{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/praveshjain/venv/lib/python3.10/site-packages (2.1.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/praveshjain/venv/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/praveshjain/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, tzdata, threadpoolctl, scipy, joblib, scikit-learn, pandas\n",
      "Successfully installed joblib-1.4.2 pandas-2.2.3 pytz-2024.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0 tzdata-2024.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes:\n",
      "Accuracy: 0.9846153846153847\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       130\n",
      "           1       0.98      0.99      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Results for SVM:\n",
      "Accuracy: 0.9807692307692307\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       130\n",
      "           1       0.98      0.98      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Results for Random Forest:\n",
      "Accuracy: 0.9807692307692307\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       130\n",
      "           1       0.97      0.99      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Results for KNN:\n",
      "Accuracy: 0.9769230769230769\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       130\n",
      "           1       0.98      0.97      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "Results for Logistic Regression:\n",
      "Accuracy: 0.9769230769230769\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       130\n",
      "           1       0.98      0.97      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Function to load data from the folder and assign labels\n",
    "def load_data_from_folder(folder_path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "                texts.append(content)\n",
    "                # Assign label based on filename starting with \"spmsga\" (spam)\n",
    "                if filename.startswith(\"spmsg\"):\n",
    "                    labels.append(1)  # Spam\n",
    "                else:\n",
    "                    labels.append(0)  # Not spam\n",
    "    return texts, labels\n",
    "\n",
    "# Load training and test data\n",
    "train_texts, train_labels = load_data_from_folder('/Users/praveshjain/Desktop/Portfolio/train_test_mails/train-mails')\n",
    "test_texts, test_labels = load_data_from_folder('/Users/praveshjain/Desktop/Portfolio/train_test_mails/test-mails')\n",
    "\n",
    "# Convert labels to pandas Series for compatibility with sklearn\n",
    "train_labels = pd.Series(train_labels)\n",
    "test_labels = pd.Series(test_labels)\n",
    "\n",
    "# Vectorization (TF-IDF)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_test = tfidf.transform(test_texts)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"SVM\": SVC(kernel='linear'),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, train_labels)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    print(f\"Results for {model_name}:\")\n",
    "    print(f\"Accuracy: {accuracy_score(test_labels, y_pred)}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(test_labels, y_pred))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Naive Bayes:\n",
      "Accuracy: 0.9846153846153847\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       130\n",
      "           1       0.98      0.99      0.98       130\n",
      "\n",
      "    accuracy                           0.98       260\n",
      "   macro avg       0.98      0.98      0.98       260\n",
      "weighted avg       0.98      0.98      0.98       260\n",
      "\n",
      "Naive Bayes model and TF-IDF vectorizer saved as naive_bayes_model.pkl and tfidf_vectorizer.pkl.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib  # for saving models\n",
    "\n",
    "# Load data from folder (assuming the function load_data_from_folder is already defined)\n",
    "train_texts, train_labels = load_data_from_folder('/Users/praveshjain/Desktop/Portfolio/train_test_mails/train-mails')\n",
    "test_texts, test_labels = load_data_from_folder('/Users/praveshjain/Desktop/Portfolio/train_test_mails/test-mails')\n",
    "\n",
    "# Convert labels to pandas Series for compatibility with sklearn\n",
    "train_labels = pd.Series(train_labels)\n",
    "test_labels = pd.Series(test_labels)\n",
    "\n",
    "# Vectorization (TF-IDF)\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X_train = tfidf.fit_transform(train_texts)\n",
    "X_test = tfidf.transform(test_texts)\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "naive_bayes_model.fit(X_train, train_labels)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = naive_bayes_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(f\"Results for Naive Bayes:\")\n",
    "print(f\"Accuracy: {accuracy_score(test_labels, y_pred)}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, y_pred))\n",
    "\n",
    "# Save the trained Naive Bayes model to a .pkl file\n",
    "model_filename = 'naive_bayes_model.pkl'\n",
    "joblib.dump(naive_bayes_model, model_filename)\n",
    "\n",
    "# Save the TF-IDF vectorizer too, since it's needed for inference\n",
    "tfidf_filename = 'tfidf_vectorizer.pkl'\n",
    "joblib.dump(tfidf, tfidf_filename)\n",
    "\n",
    "print(f\"Naive Bayes model and TF-IDF vectorizer saved as {model_filename} and {tfidf_filename}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for the given text is: Spam\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load the saved Naive Bayes model and TF-IDF vectorizer\n",
    "model_filename = 'naive_bayes_model.pkl'\n",
    "tfidf_filename = 'tfidf_vectorizer.pkl'\n",
    "\n",
    "naive_bayes_model = joblib.load(model_filename)\n",
    "tfidf_vectorizer = joblib.load(tfidf_filename)\n",
    "\n",
    "# Function to predict whether a given text is spam or not\n",
    "def predict_spam(text):\n",
    "    # Transform the text using the saved TF-IDF vectorizer\n",
    "    text_transformed = tfidf_vectorizer.transform([text])\n",
    "    \n",
    "    # Predict using the loaded Naive Bayes model\n",
    "    prediction = naive_bayes_model.predict(text_transformed)\n",
    "    \n",
    "    # Return the result\n",
    "    return \"Spam\" if prediction == 1 else \"Not Spam\"\n",
    "\n",
    "# Example usage\n",
    "new_text = \"Congratulations! You've won a free iPhone. Click here to claim your prize.\"\n",
    "result = predict_spam(new_text)\n",
    "print(f\"The prediction for the given text is: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
